{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\practice\\talk_assistant\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "from transformers import AutoTokenizer, set_seed\n",
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\scrape_multiple_file\\02_file\\virtual\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "e:\\scrape_multiple_file\\02_file\\virtual\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-mini-expresso\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-mini-expresso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the model-agnostic default `max_length` (=2580) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n"
     ]
    }
   ],
   "source": [
    "# prompt = '''In the image, there is a man and a woman sitting on grass with their arms around each other. They seem to be embracing or\n",
    "# cuddling close together, indicating a display of affection or intimacy. The couple appears to be enjoying each other's company in\n",
    "# what could be described as an outdoor setting, possibly a park or garden.'''\n",
    "prompt = '''Twinkle, twinkle, little star\n",
    "How I wonder what you are\n",
    "Up above the world so high\n",
    "Like a diamond in the sky\n",
    "Twinkle, twinkle, little star\n",
    "How I wonder what you are'''\n",
    "#description = \"Talia in engaging voice and modrate quality audio\"\n",
    "description = \"Talia is singing a poem\"\n",
    "\n",
    "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n",
    "prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "set_seed(42)\n",
    "generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n",
    "audio_arr = generation.cpu().numpy().squeeze()\n",
    "sf.write(\"05.wav\", audio_arr, model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "def record_and_save_audio(filename, duration=5):\n",
    "    \"\"\"\n",
    "    Records audio from the default input device, saves it to a WAV file,\n",
    "    and resamples it to 16000 Hz.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Filename to save the WAV file to.\n",
    "        duration (int): Recording duration in seconds.\n",
    "    \"\"\"\n",
    "    # Open the default input device\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=44100, input=True, frames_per_buffer=1024)\n",
    "\n",
    "    # Record audio\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    for i in range(0, int(44100 / 1024 * duration)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "\n",
    "    # Close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Save the recorded audio to a WAV file\n",
    "    wf = wave.open(filename + '.wav', 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(2)\n",
    "    wf.setframerate(44100)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    print(filename + '.wav'+ 'saved')\n",
    "    # Load the recorded audio\n",
    "    #audio_data, sample_rate = torchaudio.load(filename + '.wav')\n",
    "\n",
    "    # # Resample the audio data to 16000 Hz\n",
    "    # resampled_audio = torchaudio.transforms.Resample(sample_rate, 16000)(audio_data)\n",
    "\n",
    "    # # Save the resampled audio data to a new WAV file\n",
    "    # torchaudio.save(filename + '_resampled.wav', resampled_audio, 16000)\n",
    "    #print(\"Recording saved to\", filename + '_resampled.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording saved to 03_resampled.wav\n"
     ]
    }
   ],
   "source": [
    "record_and_save_audio('03', duration=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import torchaudio\n",
    "import torch\n",
    "import tkinter as tk\n",
    "from threading import Thread\n",
    "\n",
    "def record_and_save_audio(filename):\n",
    "    \"\"\"\n",
    "    Records audio from the default input device and saves it to a WAV file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Filename to save the WAV file to.\n",
    "    \"\"\"\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "\n",
    "    def stop_recording():\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        wf = wave.open(filename + '.wav', 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "\n",
    "        print(\"Recording saved to\", filename + '.wav')\n",
    "\n",
    "    def start_recording():\n",
    "        while True:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "    recording_thread = Thread(target=start_recording)\n",
    "    recording_thread.start()\n",
    "\n",
    "    return stop_recording\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Audio Recorder\")\n",
    "\n",
    "    def start_recording_callback():\n",
    "        recording_button.config(state='disabled')\n",
    "        stop_recording_button.config(state='normal')\n",
    "        stop_recording = record_and_save_audio('output')\n",
    "        stop_recording_button.config(command=stop_recording)\n",
    "\n",
    "    def stop_recording_callback():\n",
    "        stop_recording_button.config(state='disabled')\n",
    "        recording_button.config(state='normal')\n",
    "\n",
    "    recording_button = tk.Button(root, text=\"Start Recording\", command=start_recording_callback)\n",
    "    recording_button.pack()\n",
    "\n",
    "    stop_recording_button = tk.Button(root, text=\"Stop Recording\", command=stop_recording_callback, state='disabled')\n",
    "    stop_recording_button.pack()\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
